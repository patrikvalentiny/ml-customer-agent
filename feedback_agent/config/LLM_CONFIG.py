LLM_CONFIG = {
    "model": "llama3.2:1b",
    "client_host": "127.0.0.1:11434",
    "api_type": "ollama",
    "hide_tools": "if_any_run"
}